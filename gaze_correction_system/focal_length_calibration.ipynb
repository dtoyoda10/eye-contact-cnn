{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please place your head in front of the camera about 50 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please insert your interpupillary distance (the distance between two eyes) in the code or use the average distance 6.3 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_IPD = 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_res = [640,480]\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./lm_feat/shape_predictor_68_face_landmarks.dat\") \n",
    "face_detect_size = [320,240]\n",
    "\n",
    "def get_eye_pos(shape, pos = \"L\"):\n",
    "    if(pos == \"R\"):\n",
    "        lc = 36\n",
    "        rc = 39\n",
    "        FP_seq = [36,37,38,39,40,41]\n",
    "    elif(pos == \"L\"):\n",
    "        lc = 42\n",
    "        rc = 45\n",
    "        FP_seq = [45,44,43,42,47,46]\n",
    "    else:\n",
    "        print(\"Error: Wrong Eye\")\n",
    "\n",
    "    eye_cx = (shape.part(rc).x+shape.part(lc).x)*0.5\n",
    "    eye_cy = (shape.part(rc).y+shape.part(lc).y)*0.5\n",
    "    eye_center = [eye_cx, eye_cy]\n",
    "    eye_len = np.absolute(shape.part(rc).x - shape.part(lc).x)\n",
    "    bx_d5w = eye_len*3/4\n",
    "    bx_h = 1.5*bx_d5w\n",
    "    sft_up = bx_h*7/12\n",
    "    sft_low = bx_h*5/12\n",
    "    E_TL = (int(eye_cx-bx_d5w),int(eye_cy-sft_up))\n",
    "    E_RB = (int(eye_cx+bx_d5w),int(eye_cy+sft_low))\n",
    "    return eye_center, E_TL, E_RB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start capturing you faces, push k if you have already placed you head about 50 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, recv_frame = vs.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(recv_frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_detect_gray = cv2.resize(gray, (face_detect_size[0], face_detect_size[1]))\n",
    "    # Detect the facial landmarks\n",
    "    detections = detector(face_detect_gray, 0)\n",
    "    x_ratio = video_res[0]/face_detect_size[0]\n",
    "    y_ratio = video_res[1]/face_detect_size[1]\n",
    "    LE_ach_maps=[]\n",
    "    RE_ach_maps=[]\n",
    "    for k,bx in enumerate(detections):\n",
    "        target_bx = dlib.rectangle(left=int(bx.left()*x_ratio), right =int(bx.right()*x_ratio),\n",
    "                                   top =int(bx.top()*y_ratio),  bottom=int(bx.bottom()*y_ratio))\n",
    "        shape = predictor(gray, target_bx)\n",
    "        # get eye\n",
    "        LE_center, L_E_TL, L_E_RB = get_eye_pos(shape, pos=\"L\")\n",
    "        RE_center, R_E_TL, R_E_RB = get_eye_pos(shape, pos=\"R\")\n",
    "\n",
    "        f = int(np.sqrt((LE_center[0]-RE_center[0])**2 + (LE_center[1]-RE_center[1])**2)*d/P_IPD)\n",
    "        cv2.rectangle(recv_frame,\n",
    "                      (video_res[0]-150,0),(video_res[0],40),\n",
    "                      (255,255,255),-1\n",
    "                     )\n",
    "        cv2.putText(recv_frame,\n",
    "                    'f:'+str(f),\n",
    "                    (video_res[0]-140,15), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(0,0,255),1,cv2.LINE_AA)\n",
    "#         cv2.line(recv_frame, (int(LE_center[0]),int(LE_center[1])), (int(RE_center[0]),int(RE_center[1])), (0,0,255))\n",
    "        \n",
    "        # eye region\n",
    "        cv2.rectangle(recv_frame,\n",
    "                      (L_E_TL[0],L_E_TL[1]),(L_E_RB[0],L_E_RB[1]),\n",
    "                      (0,0,255),1\n",
    "                     )\n",
    "        cv2.rectangle(recv_frame,\n",
    "                      (R_E_TL[0],R_E_TL[1]),(R_E_RB[0],R_E_RB[1]),\n",
    "                      (0,0,255),1\n",
    "                     )\n",
    "        cv2.circle(recv_frame,(int(LE_center[0]),int(LE_center[1])), 2, (0,255,0), -1)\n",
    "        cv2.circle(recv_frame,(int(RE_center[0]),int(RE_center[1])), 2, (0,255,0), -1)\n",
    "        for i in range(68):\n",
    "            cv2.circle(recv_frame,(shape.part(i).x,shape.part(i).y), 2, (0,0,255), -1)\n",
    "    \n",
    "    cv2.imshow(\"Calibration\", recv_frame)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"focal length is \", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
